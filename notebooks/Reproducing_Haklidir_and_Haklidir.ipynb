{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6eb5cb",
   "metadata": {},
   "source": [
    "# Reproducing Haklidir & Haklidir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7c032",
   "metadata": {},
   "source": [
    "We are going to try to reproduce a paper on machine learning in a geothermal setting:\n",
    "\n",
    "> Tut Haklidir, F.S., & Haklidir, M. (2019). Prediction of Reservoir Temperatures Using Hydrogeochemical Data, Western Anatolia Geothermal Systems (Turkey): A Machine Learning Approach. _Natural Resources Research_, **29**, 2333-2346. [DOI:10.1007/s11053-019-09596-0](https://link.springer.com/article/10.1007%2Fs11053-019-09596-0)\n",
    "\n",
    "I first heard of this work at the 2020 World Geothermal Congress (which was in 2021) during this talk: https://www.youtube.com/watch?v=-Y0fb23FDzI. The talk frames the task as a classification task, predicting classes of temperature (high, medium, low). But it seems more sensible to cast this as a regression, and that's what the paper does. As far as I can tell, the two papers use the same dataset (but it's hard to be certain).\n",
    "\n",
    "Plan:\n",
    "\n",
    "- Load the data.\n",
    "- Try to reproduce the figures in the journal article.\n",
    "- Try to reproduce the results in the conference paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563410c8",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "You can see the process of loading and cleaning the original data from the paper [in this original 'reproduction'](https://github.com/softwareunderground/repro-zoo/blob/main/haklidir-and-haklidir-2019/Reproducing_models.ipynb) at the Software Underground Repro Zoo repo. I'll spare you the grisly details here :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2642c4e0",
   "metadata": {},
   "source": [
    "Load the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6694780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/scienxlab/datasets/refs/heads/main/misc/haklidir-and-haklidir-2019.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793d2082",
   "metadata": {},
   "source": [
    "**Note that there are two samples labeled 35 and no sample 63. This is how the dataset was published.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8586a1f",
   "metadata": {},
   "source": [
    "## Question about the temperatures\n",
    "\n",
    "I believe the adiabatic (i.e. with steam loss, for open systems) silica geothemometry equation for high-temperature systems (over 150 deg C) is:\n",
    "\n",
    "$$ T = \\frac{1522}{5.75 - log(S)} - 273.15  $$\n",
    "\n",
    "where $S$ is in mg/kg. There are adjustments to the parameters in this equation for low temperature systems.\n",
    "\n",
    "The problem here is that if T was calculated from SiO<sub>2</sub> then all we can achieve with machine learning is the discovery of that linear relationship. So I'm inclined to throw out the data from thermal springs — unfortunately it's a lot of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Source type']=='Thermal spring'].count()['Sample label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d40f78",
   "metadata": {},
   "source": [
    "So only 23 samples out of 83 are from wells.\n",
    "\n",
    "Let's compute this temperature and see if we can figure out where the numbers in the temperature column came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def geotemp(S: float) -> float:\n",
    "    \"\"\"\n",
    "    Fournier 1977 equation for temperature from silica,\n",
    "    without steam loss.\n",
    "    \"\"\"\n",
    "    return 1522 / (5.75 - np.log10(S)) - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add geothermometry as feature.\n",
    "df['Geothermometry'] = df['SiO2 (mg/l)'].map(geotemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "is_spring = lambda x: x=='Thermal spring'\n",
    "\n",
    "plt.scatter(df['Geothermometry'],\n",
    "            df['Reservoir temperature (°C)'],\n",
    "            c=is_spring(df['Source type']), cmap='bwr',\n",
    "            s=30*((1+(df['Dataset']!=\"Training\"))/2),  # Validation points are larger.\n",
    "            alpha=((1+(df['Dataset']==\"Training\"))/2)  # Validation points are semi-transp.\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae60bc",
   "metadata": {},
   "source": [
    "Wow.\n",
    "\n",
    "So to obtain the reservoir temperature, which is the target of their machine learning task, the authors applied this equation to the silica concentration even though:\n",
    "\n",
    "1. They are trying to predict temperature from the geochemistry.\n",
    "1. The equation is not appropriate for temperatures below about 150 degC. (This doesn't really matter though, becase of the first point.)\n",
    "\n",
    "This undermines the entire piece of work, limiting it to the 23 samples from wells that have independent measures of temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9177113",
   "metadata": {},
   "source": [
    "## Create `X` and `y` and split the data\n",
    "\n",
    "The authors state in Figure 4 they were using **Temperature** as input, as well as output. But they can't have been doing that because it would lead to perfect predictions. So I'm not sure what that feature is and assume it was a mistake to indicate it as an input.\n",
    "\n",
    "They also state that they did use SiO<sub>2</sub>, even though it was used to compute the target. I've checked the models with and without this feature, and whether I use it or not, I cannot reproduce their results, so it's hard to say. I hope they did not use it, but I suspect they did (indeed, the errors I get are more in line with theirs if I do use it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pH', 'EC (microS/cm)', 'K (mg/l)', 'Na (mg/l)', 'Boron (mg/l)', 'SiO2 (mg/l)', 'Cl (mg/l)']\n",
    "target = 'Reservoir temperature (°C)'\n",
    "\n",
    "# Conditions.\n",
    "train = df['Dataset']=='Training'\n",
    "val = df['Dataset']=='Validation'\n",
    "well = df['Source type']=='Well'\n",
    "\n",
    "X_train = df.loc[train & well, features]\n",
    "y_train = df.loc[train & well, target]\n",
    "X_val = df.loc[val & well, features]\n",
    "y_val = df.loc[val & well, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12659cc9",
   "metadata": {},
   "source": [
    "## Standardize the data\n",
    "\n",
    "The authors do not say if they did this or not. Since the scales of the inputs vary so widely, and since we're using models like SVM and a neural network, it's an important step. For now we'll just scale the inputs, but the neural net will probably perform better with scaled output as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aaf586",
   "metadata": {},
   "source": [
    "### Train and predict: Linear regression\n",
    "\n",
    "The authors don't say if they were using regularization or not, but we want the best result possible so we'll use it. I tuned it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "model = Ridge(alpha=10)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "y_hat = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "print(f'RMSE for linear regression: {rmse:.1f} deg C')\n",
    "print(f'MAE for linear regression: {mae:.1f} deg C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6af061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "\n",
    "fig7a = 'https://raw.githubusercontent.com/softwareunderground/repro-zoo/main/haklidir-and-haklidir-2019/Fig7a.png'\n",
    "\n",
    "im = np.array(Image.open(urlopen(fig7a)))\n",
    "extent = [-3.8, 296, 9, 295]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(im, origin='upper', extent=extent)\n",
    "plt.scatter(y_train, y_hat, alpha=0.5, s=70, c='c')\n",
    "plt.scatter(y_val, y_pred, c='C1', alpha=0.75)\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530a03f",
   "metadata": {},
   "source": [
    "### Train and predict: linear SVM\n",
    "\n",
    "Again the authors don't say if they applied regularization or not. We'll use it (it's on by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7439f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm = SVR(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_val)\n",
    "y_hat = svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47876128",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "print(f'RMSE for linear SVM: {rmse:.1f} deg C')\n",
    "print(f'MAE for linear SVM: {mae:.1f} deg C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551199d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7b = \"https://raw.githubusercontent.com/softwareunderground/repro-zoo/main/haklidir-and-haklidir-2019/Fig7b.png\"\n",
    "im = np.array(Image.open(urlopen(fig7b)))\n",
    "extent = [5, 270, 14, 275]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(im, origin='upper', extent=extent)\n",
    "plt.scatter(y_train, y_hat, alpha=0.4, s=80, c='c')\n",
    "plt.scatter(y_val, y_pred, c='C1', alpha=0.75)\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71fd9c3",
   "metadata": {},
   "source": [
    "### Non-linear SVM\n",
    "\n",
    "I was curious how this would do in comparison.\n",
    "\n",
    "Let's tune the regularization parameter `C` a bit to get a reasonable fit without overtraining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058863a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-1, 4, 11)\n",
    "trains, vals = [], []\n",
    "\n",
    "for C in Cs:\n",
    "    svm = SVR(C=C)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_val)\n",
    "    y_hat = svm.predict(X_train)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_hat, y_train))\n",
    "\n",
    "    trains.append(rmse_train)\n",
    "    vals.append(rmse)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Cs, trains, 'o-')\n",
    "plt.plot(Cs, vals, 'o-')\n",
    "plt.xscale('log')\n",
    "plt.grid(c='k', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cbest = Cs[np.argmin(vals)]\n",
    "Cbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVR(C=Cbest)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_val)\n",
    "y_hat = svm.predict(X_train)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "print(f'RMSE for non-linear SVM: {rmse:.1f} deg C')\n",
    "print(f'MAE for non-linear SVM: {mae:.1f} deg C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d617d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [5, 270, 14, 275]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(im, origin='upper', extent=extent)\n",
    "plt.scatter(y_train, y_hat, alpha=0.4, s=80, c='c')\n",
    "plt.scatter(y_val, y_pred, c='C1')\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e84be7",
   "metadata": {},
   "source": [
    "Clearly much better (and the fit to the training data is, not surprisingly, almost perfect)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbbb47b",
   "metadata": {},
   "source": [
    "### Train and predict: Neural network\n",
    "\n",
    "First let's scale the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yscaler = StandardScaler()\n",
    "yscaler.fit(y_train.values.reshape(-1, 1))\n",
    "y_train_ = yscaler.transform(y_train.values.reshape(-1, 1)).squeeze()\n",
    "y_val_ = yscaler.transform(y_val.values.reshape(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca8933",
   "metadata": {},
   "source": [
    "The authors do not say (in the talk, or in the paper) what the architecture of their network is, although the figure implies that it has 2 hidden layers (i.e. not including input or output).\n",
    "\n",
    "They also don't mention the activation function, optimization strategy, regularization applied... or basically give any details at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "net = MLPRegressor(hidden_layer_sizes=(5, 5),\n",
    "                   max_iter=500,\n",
    "                   random_state=42,\n",
    "                  )\n",
    "net.fit(X_train, y_train_)\n",
    "y_pred_ = net.predict(X_val)\n",
    "y_hat_ = net.predict(X_train)\n",
    "\n",
    "# It would be much smarter to use TransformedTargetRegressor here!\n",
    "y_pred = yscaler.inverse_transform(y_pred_.reshape(-1, 1))\n",
    "y_hat = yscaler.inverse_transform(y_hat_.reshape(-1, 1))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "print(f'RMSE for neural net: {rmse:.1f} deg C')\n",
    "print(f'MAE for neural net: {mae:.1f} deg C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7c = \"https://raw.githubusercontent.com/softwareunderground/repro-zoo/main/haklidir-and-haklidir-2019/Fig7c.png\"\n",
    "im = np.array(Image.open(urlopen(fig7c)))\n",
    "extent = [22, 264, 37, 251]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(im, origin='upper', extent=extent)\n",
    "plt.scatter(y_train, y_hat, alpha=0.4, s=80, c='c')\n",
    "plt.scatter(y_val, y_pred, c='C1', alpha=0.75)\n",
    "plt.plot([60, 240], [60, 240], c='r')\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68afaf",
   "metadata": {},
   "source": [
    "Note that the $x = y$ line in the published plot is incorrect so I plotted a new one (red).\n",
    "\n",
    "Safe to say that our results do not agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0232a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7f69571",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "&copy; 2023 Matt Hall, licensed CC BY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
